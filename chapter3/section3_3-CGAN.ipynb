{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"section3_3-CGAN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"rE5GXEzgn-p1"},"source":["# 準備"]},{"cell_type":"code","metadata":{"id":"MLyQpZLTse-n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612066217951,"user_tz":-540,"elapsed":719,"user":{"displayName":"毛利拓也","photoUrl":"","userId":"17854120745961292401"}},"outputId":"c5bb9ca4-6df4-47c1-ff67-04342e7638a1"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sun Jan 31 04:10:16 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4JSI-ob1LXJ3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612066237288,"user_tz":-540,"elapsed":4470,"user":{"displayName":"毛利拓也","photoUrl":"","userId":"17854120745961292401"}},"outputId":"f21ba36c-8a85-40fc-8028-a6fec39c3df1"},"source":["# バージョン指定時にコメントアウト\n","#!pip install torch==1.7.0\n","#!pip install torchvision==0.8.1\n","\n","import torch\n","import torchvision\n","# バージョンの確認\n","print(torch.__version__) \n","print(torchvision.__version__) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.7.0+cu101\n","0.8.1+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VGlfMTUfa-It","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612066272320,"user_tz":-540,"elapsed":24418,"user":{"displayName":"毛利拓也","photoUrl":"","userId":"17854120745961292401"}},"outputId":"70f3b734-3044-4072-cd22-a2af6afcc96a"},"source":["# Google ドライブにマウント\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GpXhG3lzbSBK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612066276177,"user_tz":-540,"elapsed":750,"user":{"displayName":"毛利拓也","photoUrl":"","userId":"17854120745961292401"}},"outputId":"decbabde-38bd-49ee-ec39-ba23d5a7f185"},"source":["%cd '/content/gdrive/MyDrive/Colab Notebooks/gan_sample/chapter3'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Colab Notebooks/gan_sample/chapter3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rfdH0jXxC-pk"},"source":["# パッケージのインポート\n","import os\n","import random\n","import numpy as np\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","import torchsummary"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UAp9p1iOC-pp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612066303003,"user_tz":-540,"elapsed":687,"user":{"displayName":"毛利拓也","photoUrl":"","userId":"17854120745961292401"}},"outputId":"8b9f79fd-e5f5-44e7-8154-2307a0d5d409"},"source":["# 設定\n","workers = 2\n","batch_size=50\n","nz = 100\n","nch_g = 128\n","nch_d = 128\n","n_epoch = 10\n","lr = 0.0002\n","beta1 = 0.5\n","outf = './result_3_3-CGAN'\n","display_interval = 600\n","\n","# 保存先ディレクトリを作成\n","try:\n","    os.makedirs(outf, exist_ok=True)\n","except OSError as error: \n","    print(error)\n","    pass\n","\n","# 乱数のシード（種）を固定\n","random.seed(0)\n","np.random.seed(0)\n","torch.manual_seed(0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7efedc26cbd0>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"usD6N-1Wo6NW"},"source":["# データセットの作成"]},{"cell_type":"code","metadata":{"id":"ETttQCP4y30H"},"source":["# MNISTの訓練データセットを読み込む\n","dataset = dset.MNIST(root='./mnist_root', download=True, train=True,\n","                      transform=transforms.Compose([\n","                          transforms.ToTensor(),\n","                          transforms.Normalize((0.5,), (0.5,)) ])) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wvn5iRLX2aJ-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612066315241,"user_tz":-540,"elapsed":787,"user":{"displayName":"毛利拓也","photoUrl":"","userId":"17854120745961292401"}},"outputId":"e6c2a934-f8e7-45ac-be05-7cc4c5548bfa"},"source":["# 画像配列の確認\r\n","dataset[0][0].shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 28, 28])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"aVJAuz2r0UH1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612066317341,"user_tz":-540,"elapsed":814,"user":{"displayName":"毛利拓也","photoUrl":"","userId":"17854120745961292401"}},"outputId":"9cd36f0d-cce6-4ba1-81e8-c3008e63cac3"},"source":["# 訓練データをセットしたデータローダーを作成する\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n","                                         shuffle=True, num_workers=int(workers))\n","\n","# 学習に使用するデバイスを得る。可能ならGPUを使用する\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print('device:', device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["device: cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o3rruPyko-8r"},"source":["# ネットワークの定義"]},{"cell_type":"code","metadata":{"id":"xmsd_MKAlXw6"},"source":["class Generator(nn.Module):\n","    \"\"\"\n","    生成器Gのクラス\n","    \"\"\"\n","    def __init__(self, nz=100, nch_g=64, nch=1):\n","        \"\"\"\n","        :param nz: 入力ベクトルzの次元\n","        :param nch_g: 最終層の入力チャネル数\n","        :param nch: 出力画像のチャネル数\n","        \"\"\"\n","        super(Generator, self).__init__()\n","\n","        # ニューラルネットワークの構造を定義する\n","        self.layers = nn.ModuleDict({\n","            'layer0': nn.Sequential(\n","                nn.ConvTranspose2d(nz, nch_g * 4, 3, 1, 0),     # 転置畳み込み\n","                nn.BatchNorm2d(nch_g * 4),                      # バッチノーマライゼーション\n","                nn.ReLU()                                       # ReLU\n","            ),  # (B, nz, 1, 1) -> (B, nch_g*4, 3, 3)\n","            'layer1': nn.Sequential(\n","                nn.ConvTranspose2d(nch_g * 4, nch_g * 2, 3, 2, 0),\n","                nn.BatchNorm2d(nch_g * 2),\n","                nn.ReLU()\n","            ),  # (B, nch_g*4, 3, 3) -> (B, nch_g*2, 7, 7)\n","            'layer2': nn.Sequential(\n","                nn.ConvTranspose2d(nch_g * 2, nch_g, 4, 2, 1),\n","                nn.BatchNorm2d(nch_g),\n","                nn.ReLU()\n","            ),  # (B, nch_g*2, 7, 7) -> (B, nch_g, 14, 14)\n","            'layer3': nn.Sequential(\n","                nn.ConvTranspose2d(nch_g, nch, 4, 2, 1),\n","                nn.Tanh()\n","            )   # (B, nch_g, 14, 14) -> (B, nch, 28, 28)\n","        })\n","\n","    def forward(self, z):\n","        \"\"\"\n","        順方向の演算\n","        :param z: 入力ベクトル\n","        :return: 生成画像\n","        \"\"\"\n","        for layer in self.layers.values():  # self.layersの各層で演算を行う\n","            z = layer(z)\n","        return z\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTK-Mvf2ldoI"},"source":["class Discriminator(nn.Module):\n","    \"\"\"\n","    識別器Dのクラス\n","    \"\"\"\n","    def __init__(self, nch=1, nch_d=64):\n","        \"\"\"\n","        :param nch: 入力画像のチャネル数\n","        :param nch_d: 先頭層の出力チャネル数\n","        \"\"\"\n","        super(Discriminator, self).__init__()\n","\n","        # ニューラルネットワークの構造を定義する\n","        self.layers = nn.ModuleDict({\n","            'layer0': nn.Sequential(\n","                nn.Conv2d(nch, nch_d, 4, 2, 1),     # 畳み込み\n","                nn.LeakyReLU(negative_slope=0.2)    # leaky ReLU関数\n","            ),  # (B, nch, 28, 28) -> (B, nch_d, 14, 14)\n","            'layer1': nn.Sequential(\n","                nn.Conv2d(nch_d, nch_d * 2, 4, 2, 1),\n","                nn.BatchNorm2d(nch_d * 2),\n","                nn.LeakyReLU(negative_slope=0.2)\n","            ),  # (B, nch_d, 14, 14) -> (B, nch_d*2, 7, 7)\n","            'layer2': nn.Sequential(\n","                nn.Conv2d(nch_d * 2, nch_d * 4, 3, 2, 0),\n","                nn.BatchNorm2d(nch_d * 4),\n","                nn.LeakyReLU(negative_slope=0.2)\n","            ),  # (B, nch_d*2, 7, 7) -> (B, nch_d*4, 3, 3)\n","            'layer3': nn.Sequential(\n","                nn.Conv2d(nch_d * 4, 1, 3, 1, 0),\n","                nn.Sigmoid()\n","            )    \n","            # (B, nch_d*4, 3, 3) -> (B, 1, 1, 1)\n","        })\n","\n","    def forward(self, x):\n","        \"\"\"\n","        順方向の演算\n","        :param x: 本物画像あるいは生成画像\n","        :return: 識別信号\n","        \"\"\"\n","        for layer in self.layers.values():  # self.layersの各層で演算を行う\n","            x = layer(x)\n","        return x.squeeze()     # Tensorの形状を(B)に変更して戻り値とする"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NkuriTFqlMfq"},"source":["def weights_init(m):\n","    \"\"\"\n","    ニューラルネットワークの重みを初期化する。作成したインスタンスに対しapplyメソッドで適用する\n","    :param m: ニューラルネットワークを構成する層\n","    \"\"\"\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:            # 畳み込み層の場合\n","        m.weight.data.normal_(0.0, 0.02)\n","        m.bias.data.fill_(0)\n","    elif classname.find('Linear') != -1:        # 全結合層の場合\n","        m.weight.data.normal_(0.0, 0.02)\n","        m.bias.data.fill_(0)\n","    elif classname.find('BatchNorm') != -1:     # バッチノーマライゼーションの場合\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BHW7ebSqtc1K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612066331462,"user_tz":-540,"elapsed":11161,"user":{"displayName":"毛利拓也","photoUrl":"","userId":"17854120745961292401"}},"outputId":"64a512b2-ab19-4694-8c99-3a1bde65fe02"},"source":["# 生成器G。ランダムベクトルから生成画像を作成する\n","netG = Generator(nz=nz+10, nch_g=nch_g).to(device) #10はn_class=10を指す。出し分けに必要なラベル情報\n","netG.apply(weights_init)    # weights_init関数で初期化\n","print(netG)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Generator(\n","  (layers): ModuleDict(\n","    (layer0): Sequential(\n","      (0): ConvTranspose2d(110, 512, kernel_size=(3, 3), stride=(1, 1))\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (layer1): Sequential(\n","      (0): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2))\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (layer2): Sequential(\n","      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (layer3): Sequential(\n","      (0): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): Tanh()\n","    )\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVxTCM5sEuED","executionInfo":{"status":"ok","timestamp":1612066352779,"user_tz":-540,"elapsed":798,"user":{"displayName":"毛利拓也","photoUrl":"","userId":"17854120745961292401"}},"outputId":"f313c86b-d8bd-4ae8-8de2-fae355006b51"},"source":["# 生成器GのTensor形状\n","torchsummary.summary(netG, (110, 1, 1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","   ConvTranspose2d-1            [-1, 512, 3, 3]         507,392\n","       BatchNorm2d-2            [-1, 512, 3, 3]           1,024\n","              ReLU-3            [-1, 512, 3, 3]               0\n","   ConvTranspose2d-4            [-1, 256, 7, 7]       1,179,904\n","       BatchNorm2d-5            [-1, 256, 7, 7]             512\n","              ReLU-6            [-1, 256, 7, 7]               0\n","   ConvTranspose2d-7          [-1, 128, 14, 14]         524,416\n","       BatchNorm2d-8          [-1, 128, 14, 14]             256\n","              ReLU-9          [-1, 128, 14, 14]               0\n","  ConvTranspose2d-10            [-1, 1, 28, 28]           2,049\n","             Tanh-11            [-1, 1, 28, 28]               0\n","================================================================\n","Total params: 2,215,553\n","Trainable params: 2,215,553\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.98\n","Params size (MB): 8.45\n","Estimated Total Size (MB): 9.43\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rriIYwAFC-pz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612066356045,"user_tz":-540,"elapsed":819,"user":{"displayName":"毛利拓也","photoUrl":"","userId":"17854120745961292401"}},"outputId":"08b110f1-93dc-41de-ad8e-1019b17deea3"},"source":["# 識別器D。画像が本物か生成かを識別する\n","netD = Discriminator(nch=1+10, nch_d=nch_d).to(device) #10はn_class=10を指す。分類に必要なラベル情報\n","netD.apply(weights_init)\n","print(netD)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Discriminator(\n","  (layers): ModuleDict(\n","    (layer0): Sequential(\n","      (0): Conv2d(11, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): LeakyReLU(negative_slope=0.2)\n","    )\n","    (layer1): Sequential(\n","      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.2)\n","    )\n","    (layer2): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.2)\n","    )\n","    (layer3): Sequential(\n","      (0): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1))\n","      (1): Sigmoid()\n","    )\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4_PWX2WGFRqb","executionInfo":{"status":"ok","timestamp":1612066358400,"user_tz":-540,"elapsed":663,"user":{"displayName":"毛利拓也","photoUrl":"","userId":"17854120745961292401"}},"outputId":"aec0671a-9491-4929-8be0-1cb21b77655b"},"source":["# 識別器DのTensor形状\n","torchsummary.summary(netD, (11, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 128, 14, 14]          22,656\n","         LeakyReLU-2          [-1, 128, 14, 14]               0\n","            Conv2d-3            [-1, 256, 7, 7]         524,544\n","       BatchNorm2d-4            [-1, 256, 7, 7]             512\n","         LeakyReLU-5            [-1, 256, 7, 7]               0\n","            Conv2d-6            [-1, 512, 3, 3]       1,180,160\n","       BatchNorm2d-7            [-1, 512, 3, 3]           1,024\n","         LeakyReLU-8            [-1, 512, 3, 3]               0\n","            Conv2d-9              [-1, 1, 1, 1]           4,609\n","          Sigmoid-10              [-1, 1, 1, 1]               0\n","================================================================\n","Total params: 1,733,505\n","Trainable params: 1,733,505\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.03\n","Forward/backward pass size (MB): 0.78\n","Params size (MB): 6.61\n","Estimated Total Size (MB): 7.42\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nbheRXWwpIn-"},"source":["# 学習の実行"]},{"cell_type":"code","metadata":{"id":"vjfl5HxRC-p1"},"source":["criterion = nn.BCELoss()    # バイナリークロスエントロピー（Sigmoid関数無し）\n","\n","# オプティマイザ−のセットアップ\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 識別器D用\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 生成器G用"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_RkjI57KDyc5"},"source":["def onehot_encode(label, device, n_class=10):\n","    \"\"\"\n","    カテゴリカル変数のラベルをOne-Hoe形式に変換する\n","    :param label: 変換対象のラベル\n","    :param device: 学習に使用するデバイス。CPUあるいはGPU\n","    :param n_class: ラベルのクラス数\n","    :return:\n","    \"\"\"\n","    eye = torch.eye(n_class, device=device)\n","    # ランダムベクトルあるいは画像と連結するために(B, c_class, 1, 1)のTensorにして戻す\n","    return eye[label].view(-1, n_class, 1, 1) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"av1H0Fo-D0UL"},"source":["def concat_image_label(image, label, device, n_class=10):\n","    \"\"\"\n","    画像とラベルを連結する\n","    :param image:　画像\n","    :param label: ラベル\n","    :param device: 学習に使用するデバイス。CPUあるいはGPU\n","    :param n_class: ラベルのクラス数\n","    :return:　画像とラベルをチャネル方向に連結したTensor\n","    \"\"\"\n","    B, C, H, W = image.shape    # 画像Tensorの大きさを取得\n","    \n","    oh_label = onehot_encode(label, device)         # ラベルをOne-Hotベクトル化\n","    oh_label = oh_label.expand(B, n_class, H, W)    # 画像のサイズに合わせるようラベルを拡張する\n","    return torch.cat((image, oh_label), dim=1)      # 画像とラベルをチャネル方向（dim=1）で連結する"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5S5mqSttD0hj"},"source":["def concat_noise_label(noise, label, device):\n","    \"\"\"\n","    ノイズ（ランダムベクトル）とラベルを連結する\n","    :param noise: ノイズ\n","    :param label: ラベル\n","    :param device: 学習に使用するデバイス。CPUあるいはGPU\n","    :return:　ノイズとラベルを連結したTensor\n","    \"\"\"\n","    oh_label = onehot_encode(label, device)     # ラベルをOne-Hotベクトル化\n","    return torch.cat((noise, oh_label), dim=1)  # ノイズとラベルをチャネル方向（dim=1）で連結する"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3pSpplj6EhjN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612066398646,"user_tz":-540,"elapsed":844,"user":{"displayName":"毛利拓也","photoUrl":"","userId":"17854120745961292401"}},"outputId":"af053533-1ee9-41c9-b242-d8d64e4e2ee0"},"source":["# 生成器のエポックごとの画像生成に使用する確認用の固定ノイズ\n","fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device) \n","# 確認用のラベル。0〜9のラベルの繰り返し\n","fixed_label = [i for i in range(10)] * (batch_size // 10)\n","fixed_label = torch.tensor(fixed_label, dtype=torch.long, device=device)\n","# 確認用のノイズとラベルを連結\n","fixed_noise_label = concat_noise_label(fixed_noise, fixed_label, device) \n","print(fixed_noise.shape)\n","print(fixed_label)\n","print(fixed_noise_label.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([50, 100, 1, 1])\n","tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3,\n","        4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n","        8, 9], device='cuda:0')\n","torch.Size([50, 110, 1, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lckGpHvMC-p5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612067046791,"user_tz":-540,"elapsed":589037,"user":{"displayName":"毛利拓也","photoUrl":"","userId":"17854120745961292401"}},"outputId":"1704506e-103f-43a5-ed00-60dacf02417e"},"source":["# 学習のループ\n","for epoch in range(n_epoch):\n","    for itr, data in enumerate(dataloader):\n","        real_image = data[0].to(device)     # 本物画像\n","        real_label = data[1].to(device)     # 本物画像に対応するラベル\n","        # 本物画像とラベルを連結\n","        real_image_label = concat_image_label(real_image, real_label, device) \n","        sample_size = real_image.size(0)    # 画像枚数\n","\n","        # 標準正規分布からノイズを生成\n","        noise = torch.randn(sample_size, nz, 1, 1, device=device)\n","        # 生成画像生成用のラベル\n","        fake_label = torch.randint(10, (sample_size,), dtype=torch.long, device=device)\n","        # ノイズとラベルを連結\n","        fake_noise_label = concat_noise_label(noise, fake_label, device)        \n","        # 本物画像に対する識別信号の目標値「1」\n","        real_target = torch.full((sample_size,), 1., device=device)\n","        # 生成画像に対する識別信号の目標値「0」\n","        fake_target = torch.full((sample_size,), 0., device=device)\n","        \n","        ############################\n","        # 識別器Dの更新\n","        ###########################\n","        netD.zero_grad()    # 勾配の初期化\n","        \n","        # 識別器Dで本物画像とラベルの組み合わせに対する識別信号を出力\n","        output = netD(real_image_label)\n","        # 本物画像に対する識別信号の損失値\n","        errD_real = criterion(output, real_target)\n","\n","        D_x = output.mean().item()  # 本物画像の識別信号の平均\n","\n","        fake_image = netG(fake_noise_label)  # 生成器Gでラベルに対応した生成画像を生成\n","        # 生成画像とラベルを連結\n","        fake_image_label = concat_image_label(fake_image, fake_label, device)   \n","        \n","        # 識別器Dで本物画像に対する識別信号を出力\n","        output = netD(fake_image_label.detach()) \n","        # 生成画像に対する識別信号の損失値\n","        errD_fake = criterion(output, fake_target)  \n","        D_G_z1 = output.mean().item()# 生成画像の識別信号の平均\n","\n","        errD = errD_real + errD_fake    # 識別器Dの全体の損失\n","        errD.backward()    # 誤差逆伝播\n","        optimizerD.step()   # Dのパラメーターを更新\n","\n","        ############################\n","        # 生成器Gの更新\n","        ###########################\n","        netG.zero_grad()    # 勾配の初期化\n","        \n","        output = netD(fake_image_label)     # 更新した識別器Dで改めて生成画像とラベルの組み合わせに対する識別信号を出力\n","        errG = criterion(output, real_target)   # 生成器Gの損失値。Dに生成画像を本物画像と誤認させたいため目標値は「1」\n","        errG.backward()     # 誤差逆伝播\n","        D_G_z2 = output.mean().item()# 更新した識別器Dによる生成画像の識別信号の平均\n","\n","        optimizerG.step()   # Gのパラメータを更新\n","\n","        if itr % display_interval == 0: \n","            print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n","                  .format(epoch + 1, n_epoch,\n","                          itr + 1, len(dataloader),\n","                          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","            \n","        if epoch == 0 and itr == 0:     # 初回に本物画像を保存する\n","            vutils.save_image(real_image, '{}/real_samples.png'.format(outf),\n","                              normalize=True, nrow=10)\n","\n","    ############################\n","    # 確認用画像の生成\n","    ############################\n","    fake_image = netG(fixed_noise_label)  # 1エポック終了ごとに確認用の生成画像を生成する\n","    vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n","                      normalize=True, nrow=10)\n","\n","    ############################\n","    # モデルの保存\n","    ############################\n","    if (epoch + 1) % 10 == 0:   # 10エポックごとにモデルを保存する\n","        torch.save(netG.state_dict(), '{}/netG_epoch_{}.pth'.format(outf, epoch + 1))\n","        torch.save(netD.state_dict(), '{}/netD_epoch_{}.pth'.format(outf, epoch + 1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1/10][1/1200] Loss_D: 1.743 Loss_G: 1.737 D(x): 0.636 D(G(z)): 0.683/0.208\n","[1/10][601/1200] Loss_D: 0.849 Loss_G: 1.176 D(x): 0.633 D(G(z)): 0.237/0.367\n","[2/10][1/1200] Loss_D: 0.859 Loss_G: 2.031 D(x): 0.789 D(G(z)): 0.401/0.159\n","[2/10][601/1200] Loss_D: 1.447 Loss_G: 1.654 D(x): 0.671 D(G(z)): 0.585/0.225\n","[3/10][1/1200] Loss_D: 1.278 Loss_G: 1.289 D(x): 0.586 D(G(z)): 0.470/0.306\n","[3/10][601/1200] Loss_D: 1.032 Loss_G: 1.219 D(x): 0.608 D(G(z)): 0.363/0.328\n","[4/10][1/1200] Loss_D: 1.041 Loss_G: 1.713 D(x): 0.701 D(G(z)): 0.466/0.199\n","[4/10][601/1200] Loss_D: 0.699 Loss_G: 1.833 D(x): 0.845 D(G(z)): 0.380/0.186\n","[5/10][1/1200] Loss_D: 1.633 Loss_G: 0.617 D(x): 0.337 D(G(z)): 0.327/0.558\n","[5/10][601/1200] Loss_D: 0.779 Loss_G: 1.522 D(x): 0.601 D(G(z)): 0.205/0.236\n","[6/10][1/1200] Loss_D: 1.378 Loss_G: 1.598 D(x): 0.397 D(G(z)): 0.297/0.233\n","[6/10][601/1200] Loss_D: 0.794 Loss_G: 1.366 D(x): 0.601 D(G(z)): 0.212/0.282\n","[7/10][1/1200] Loss_D: 1.308 Loss_G: 1.459 D(x): 0.728 D(G(z)): 0.582/0.260\n","[7/10][601/1200] Loss_D: 1.118 Loss_G: 1.193 D(x): 0.496 D(G(z)): 0.289/0.326\n","[8/10][1/1200] Loss_D: 1.299 Loss_G: 1.406 D(x): 0.668 D(G(z)): 0.546/0.272\n","[8/10][601/1200] Loss_D: 1.070 Loss_G: 1.604 D(x): 0.693 D(G(z)): 0.469/0.221\n","[9/10][1/1200] Loss_D: 1.710 Loss_G: 0.706 D(x): 0.267 D(G(z)): 0.232/0.521\n","[9/10][601/1200] Loss_D: 1.039 Loss_G: 1.059 D(x): 0.537 D(G(z)): 0.299/0.371\n","[10/10][1/1200] Loss_D: 1.245 Loss_G: 1.221 D(x): 0.498 D(G(z)): 0.355/0.320\n","[10/10][601/1200] Loss_D: 0.948 Loss_G: 1.400 D(x): 0.555 D(G(z)): 0.245/0.273\n"],"name":"stdout"}]}]}